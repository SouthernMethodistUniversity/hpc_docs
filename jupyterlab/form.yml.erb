<%-
require 'open3'
begin
    # get queues from 
    script = '/hpc/applications/anaconda/3/bin/conda info -e'
    o, status = Open3.capture2('bash', stdin_data: script)
    output = o.split("\n")
    conda_envs = []
    python3_module = [ "python/3",    "python/3" ]
    custom_env = [ "Custom Environment - only use what is specified below", "custom"   ]
    conda_envs.push(python3_module)
    conda_envs.push(custom_env)
    enabled_envs = []
    disabled_envs = []
    output.each do |env|
      # skip envs in /hpc/applications
      if env =~ /^((?!hpc\/applications).)*$/ && env[0] != '#'
        split_env = env.gsub(/\s+/m, ' ').strip.split(" ")
        if split_env.count == 1
          split_env.push(split_env[0])
        end
        jupyter_path = split_env[1] + "/bin/jupyter-lab"
        if File.file?(jupyter_path)
          split_env[0] = "(Conda Environment) " + split_env[0]
          enabled_envs.push(split_env)
        else
          split_env[1] = "No Jupyter Lab"
          disabled_envs.push(split_env)
        end
      end
    end
    enabled_envs.each do |env|
      conda_envs.push(env)
    end
    disabled_envs.each do |env|
      conda_envs.push(env)
    end
end
-%>
---
cluster: "slurm_cluster"
form:
  - custom_queue
  - python_version
  - environment
  - bc_num_hours
  - bc_num_slots
  - bc_num_cores
  - bc_num_gpus
  - bc_num_memory
  - start_time
  - end_time
  - bc_email_on_started
# Define attribute values that aren't meant to be modified by the user within
# the Dashboard form
attributes:
  python_version:
    label: "Select Python Environment"
    widget: select
    help: |
      - *python/3* is the default Anaconda Python 3 installation on M2 in the module "python/3"
      - We've listed your *Conda* environments we found in standard locations. If the one you want to use is greyed out, it means that you need to install jupyterlab in that environment before it can be used
      - Environments using *venv*, *virtualenv*, and others will not be listed above and should be loaded below in the "Custom Environment" settings
      - Other environments can be specified by selecting "Custom Environment"
    options:
      <%- conda_envs.each do |q| -%>
        - [ "<%= q[0] %>", "<%= q[1] %>" ]
      <%- end -%>
  environment:
    widget: text_area
    label: "Custom environment settings"
    help: |
      - Load any addition enviroment settings
      - Use *source path/to/environment/bin/activate* to load *pip* virtual environments from *venv* or *virtualenv*
      - Use *module load module1 module2 module3* to load M2 modules
      - Use *export MY_VARIABLE=my_value* to export shell variables
      - **NOTE:**  *jupyter-lab* must be available in your environment, if we can't find it we will load the version in the module "python/3" which may conflict with the settings you provided

  bc_num_hours:
    id: bc_num_hours
    label: Time (Hours)
    help: |
      - Number of hours to allocate
      - Exceeding walltime time will automaticaly stop this job.
    cacheable: true
    widget: number_field
    max: 24
    min: 1
    step: 1
    value: 1
  bc_num_slots:
    id: num_nodes
    label: Number of nodes
    help: Number of computer nodes 
    cacheable: true
    widget: number_field
    max: 81
    min: 1
    step: 1
    value: 1
  bc_num_cores:
    id: num_cpus
    label: "Cores per node"
    help: Number of CPU threads
    cacheable: true
    widget: number_field
    max: 36
    min: 1
    value: 1
  bc_num_gpus:
    id: num_gpus
    label: "GPUs per node"
    cacheable: true
    widget: number_field
    max: 1
    min: 0
    step: 1
    value: 0
  bc_num_memory:
    id: num_mem
    label: "Memory"
    help: "Please select the amount of memory (in GB) you need for your job."
    widget: number_field
    max: 250
    min: 1
    step: 1
    value: 6
  custom_queue:
    label: "Partition"
    help: |
      Please select an [M2 SLURM partition] to submit from the drop-down.
      NOTE: Queues designated with asterisks(*) contain [faculty partner nodes] primarily intended for use by specific faculty and their research groups and as such impose some restrictions, including the possibility of job pre-emption, on jobs submitted by those outside those teams.
      [M2 SLURM partition]: https://s2.smu.edu/hpc/documentation/slurm.html#maneframe-ii-s-slurm-partitions-queues
      [faculty partner nodes]: https://s2.smu.edu/hpc/documentation/about.html#faculty-partner-nodes
    widget: select
    options:
      - [ "development [Max Time: 2 hours]",             "development"    ]
      - [ "htc [Max Time: 24 hours, Maximum Nodes: 1]",  "htc"            ]
      - [ "standard-mem-s [Max Time: 24 hours]",         "standard-mem-s" ]
      - [ "standard-mem-m [Max Time: 7 days]",           "standard-mem-m" ]
      - [ "standard-mem-l [Max Time: 30 days]",          "standard-mem-l" ]
      - [ "medium-mem-1-s [Max Time: 24 hours]",         "medium-mem-1-s" ]
      - [ "medium-mem-1-m [Max Time: 7 days]",           "medium-mem-1-m" ]
      - [ "medium-mem-1-l [Max Time: 30 days]",          "medium-mem-1-l" ]
      - [ "medium-mem-2 [Max Time: 14 days]",            "medium-mem-2"   ]
      - [ "high-mem-1 [Max Time: 14 days]",              "high-mem-1"     ]
      - [ "high-mem-2 [Max Time: 14 days]",              "high-mem-2"     ]
      - [ "mic [Max Time: 14 days]",                     "mic"            ]
      - [ "gpgpu-1 [Max Time: 7 days]",                  "gpgpu-1"        ]
      - [ "v100x8 [Max Time: 7 days]",                   "v100x8"         ]
      - [ "*fp-gpgpu-2 [Max Time: UNLIMITED]",           "fp-gpgpu-2"     ]
      - [ "*fp-gpgpu-3 [ssMax Time: UNLIMITED]",           "fp-gpgpu-3"     ]
      - [ "*fp-gpgpu-4 [Max Time: UNLIMITED]",           "fp-gpgpu-4"     ]
  start_time:
    label: "Earliest Start Time"
    id: start
    help: "Specify earliest desired start time. Leave blank to start as soon as resources are available"
    widget: datetime_field
  end_time:
    label: "Latest Start Time"
    id: end
    help: |
        Specify latest allowable start time. Leave blank to allow job to queue with no limits.
        **Jobs that do not start before this time will automatically be cancelled.**
    widget: datetime_field
